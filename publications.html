<!DOCTYPE HTML>
<html>
	<head>
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
        <script type="text/javascript">

            $( document ).ready(function() {
                $("#header").load("html/left_bar.html");
                $("#footer").load("html/footer.html");
                $("#script").load("html/ref.html");
            });

        </script>
    
        <!-- Script -->
        <div id='script'></div>  
	</head>
	<body id="top" style="visibility:hidden">

		<!-- Header -->
		<header id="header">
				
		</header>

		<!-- Main -->
			<div id="main">
                <section id="publication">
                    <h2><b>Publication</b></h2>
                    <div class="table-wrapper">
                        <table>
                            <tbody>
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/2111.01320.pdf">AVASpeech-SMAD: A Strongly Labelled Speech and Music Activity Detection Dataset with Label Co-Occurrence
                                    </a>
                                    <p class="publication">Yun-Ning Hung, Karn N. Watcharasupat, Chih-Wei Wu, Iroro Orife, Kelian Li, Pavan Seshadri, Junyoung Lee</p>
                                    <p class="publication">22th International Society for Music Information Retrieval (ISMIR) conference late-breaking demo</p>
                                    </td>
                                    <td>2021</br>
                                        
                                    </td>
                                </tr>
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/2010.11904.pdf">Transcription Is All You Need: Learning to Separate Musical Mixtures with Score as Supervision</a>
                                    <p class="publication">Yun-Ning Hung, Gordon Wichern, Jonathan Le Roux</p>
                                    <p class="publication">2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</p>
                                    </td>
                                    <td>2021</br>
                                        
                                    </td>
                                </tr>
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/2008.00616.pdf">Multitask learning for instrument activation aware music source separation</a>
                                    <p class="publication">Yun-Ning Hung, Alexander Lerch</p>
                                    <p class="publication">21th International Society for Music Information Retrieval (ISMIR) conference</p>
                                    </td>
                                    <td>2020</br>
                                        <a href="https://github.com/biboamy/Source_Separation_Inst" class="fab fa-github"><span class="label">Github</span></a>
                                        <a href="https://musicinformatics.gatech.edu/conferences/multi-task-learning-for-instrument-activation-aware-music-source-separation/" class="fa fa-globe"><span class="label">Blog</span></a>
                                    </td>
                                </tr>
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/2008.00203.pdf">Score-informed Networks for Music Performance Assessment</a>
                                    <p class="publication">Yun-Ning Hung, Alexander Lerch</p>
                                    <p class="publication">21th International Society for Music Information Retrieval (ISMIR) conference</p>
                                    </td>
                                    <td>2020</br>
                                        <a href="https://github.com/biboamy/FBA-Fall19" class="fab fa-github"><span class="label">Github</span></a>
                                    </td>
                                    </td>
                                </tr>
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/1905.13567.pdf">Musical Composition Style Transfer via Disentangled Timbre Representation</a>
                                    <p class="publication">Yun-Ning Hung, I-Tung Chiang, Yi-An Chen, Yi-Hsuan Yang</p>
                                    <p class="publication">2019 Proc. Int. Joint Conf. Artificial Intelligence (IJCAIâ€™19)</p>
                                    </td>
                                    <td>2019 </br>
                                        <a href="https://github.com/biboamy/instrument-disentangle" class="fab fa-github"><span class="label">Github</span></a>
                                        <a href="https://biboamy.github.io/disentangle_demo/result/index.html" class="fa fa-globe"><span class="label">Website</span></a>
                                        <a href="https://biboamy.github.io/disentangle_demo/IJCAI_2019_style_transfer.pptx" class="fas fa-file-pdf"><span class="label">Slide</span></a>
                                    </td>
                                </tr>
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/1811.01143.pdf">Multitask learning for frame-level instrument recognition</a>
                                    <p class="publication">Yun-Ning Hung, Yi-An Chen, Yi-Hsuan Yang</p>
                                    <p class="publication">2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</p>
                                    </td>
                                    <td>2019</br>
                                        <a href="https://github.com/biboamy/instrument-streaming" class="fab fa-github"><span class="label">Github</span></a>
                                        <a href="https://biboamy.github.io/streaming-demo/main_site/index.html" class="fa fa-globe"><span class="label">Website</span></a>
                                        <a href=" https://biboamy.github.io/streaming-demo/source/multitask%20learning-icassp2019-poster.pdf" class="fas fa-file-pdf"><span class="label">Poster</span></a>
                                    </td>
                                </tr> 
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/1811.03271.pdf">Learning Disentangled Representations for Timber and Pitch in Music Audio</a>
                                    <p class="publication">Yun-Ning Hung, Yi-An Chen, Yi-Hsuan Yang</p>
                                    <p class="publication">arXiv preprint arXiv:1710.10814</p>
                                    </td>
                                    <td>2018 </td>
                                </tr>
                                <tr>
                                    <td class="black">
                                    <a href="http://ismir2018.ircam.fr/doc/pdfs/55_Paper.pdf">Frame-level Instrument Recognition by Timbre and Pitch</a>
                                    <p class="publication">Yun-Ning Hung, Yi-Hsuan Yang</p>
                                    <p class="publication">19th International Society for Music Information Retrieval (ISMIR) conference</p>
                                    </td>
                                    <td>2018 <br>
                                        <a href="https://github.com/biboamy/instrument-prediction" class="fab fa-github"><span class="label">Github</span></a>
                                        <a href="https://biboamy.github.io/instrument-demo/index.html" class="fa fa-globe"><span class="label">Website</span></a>
                                        <a href="https://biboamy.github.io/instrument-demo/source/amy-ismir2018-slide.pdf" class="fas fa-file-pdf"><span class="label">Slide</span></a>
                                        <a href="https://biboamy.github.io/instrument-demo/source/amy-ismir2018-poster.pdf" class="fas fa-file-pdf"><span class="label">Poster</span></a>
                                    </td>
                                </tr> 
                                <tr>
                                    <td class="black">
                                    <a href="https://arxiv.org/pdf/1710.10814.pdf">Hit Song Prediction for Pop Music by Siamese CNN with Ranking Loss</a>
                                    <p class="publication">Lang-Chi Yu, Yi-Hsuan Yang, Yun-Ning Hung, Yi-An Chen</p>
                                    <p class="publication">arXiv preprint arXiv:1710.10814</p>
                                    </td>
                                    <td>2017</td>
                                </tr> 
                            </tbody>
                        </table>
                    </div>
                </section>
            </div>
				
			
		<!-- Footer -->
			<footer id="footer">
				
			</footer>

	</body>
</html>
